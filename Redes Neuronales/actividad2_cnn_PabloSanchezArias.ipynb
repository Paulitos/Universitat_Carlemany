{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4eGCEaXaDXs"
      },
      "source": [
        "# **Actividad 2**: Convolutional Neural Networks (CNNs)\n",
        "\n",
        "En la primera parte de esta actividad veremos los conceptos necesarios para implementar una Convolutional Neural Network usando Keras. Luego, tendreis que entrenar una CNN para que resuelva la tarea de clasificación de imágenes del dataset Fashion MNIST.\n",
        "\n",
        "**EVALUACIÓN**: En esta segunda práctica, tendreis completar el esqueleto del notebook y redactar un informe de 2/3 páginas explicando:\n",
        "* La arquitectura del modelo y la justificación de las decisiones de diseño.\n",
        "* El impacto del aumento de datos en el rendimiento del modelo.\n",
        "* El impacto del uso de transfer learning y de un modelo preentrenado.\n",
        "* Los desafíos encontrados durante la implementación y cómo se resolvieron.\n",
        "* La precisión final obtenida y observaciones sobre el rendimiento del modelo comparado con las previas implementaciones con la FNN.\n",
        "\n",
        "La nota de la actividad esta divida en un 50% para la evaluación del notebook y un 50% para la evaluación del informe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jXpCep16unM0"
      },
      "outputs": [],
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "from keras.layers import Activation, Dense, Input\n",
        "from keras.layers import Conv2D, Flatten\n",
        "from keras.layers import Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOcv5errc_uE"
      },
      "source": [
        "## Implementando una CNN para Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9-ekeLokdbH"
      },
      "source": [
        "## Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoO8BmzDjaAh"
      },
      "source": [
        "Con la siguiente función creamos una capa Conv2D con 32 filtros, cada uno de 3 × 3, usando un stride de 1 (tanto horizontal como vertical) y padding \"same\", y aplicando la función de activación ReLU a sus salidas.\n",
        "\n",
        "`conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aprh2-j8kCHp"
      },
      "source": [
        "Por otro lado, la siguiente función crea una capa de max pooling usando un kernel de 2 × 2. Los strides por defecto son del tamaño del kernel, por lo que esta capa usará un stride de 2 (tanto horizontal como verticalmente). Por defecto, utiliza padding \"valid\" (es decir, sin padding):\n",
        "\n",
        "```\n",
        "max_pool = keras.layers.MaxPool2D(pool_size=2)\n",
        "```\n",
        "Para crear una capa de average pooling, simplemente usaremos AvgPool2D en lugar de MaxPool2D.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pool = keras.layers.AvgPool2D(pool_size=2)"
      ],
      "metadata": {
        "id": "MTzfPIj6-831"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec7-Z997lcE5"
      },
      "source": [
        "Las arquitecturas típicas de CNN apilan unas cuantas capas convolucionales (cada una generalmente seguida por una capa ReLU), luego una capa de pooling, luego otras pocas capas convolucionales (+ReLU), luego otra capa de pooling, y así sucesivamente. La imagen se hace cada vez más pequeña a medida que avanza a través de la red, pero también generalmente se hace más profunda (es decir, con más filtros), gracias a las capas convolucionales. La capa final produce la predicción (en el caso de clasifiación le aplicamos una capa softmax que da como resultado las probabilidades de las clases).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZgMNO3yeIrNF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "3284859c-2eee-4ae5-f40d-0068cc0fab0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nmodel = keras.models.Sequential([\\n       keras.layers.Conv2D(..., ..., activation=\"relu\", padding=\"same\", input_shape=...),\\n       keras.layers.MaxPooling2D(...),\\n       keras.layers.Conv2D(..., ..., activation=\"relu\", padding=\"same\"),\\n       keras.layers.Conv2D(..., ..., activation=\"relu\", padding=\"same\"),\\n       keras.layers.MaxPooling2D(...),\\n       keras.layers.Flatten(),\\n       keras.layers.Dense(..., activation=\"relu\"),\\n       keras.layers.Dropout(...),\\n       keras.layers.Dense(..., activation=\"softmax\")\\n])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "\"\"\"\n",
        "model = keras.models.Sequential([\n",
        "       keras.layers.Conv2D(..., ..., activation=\"relu\", padding=\"same\", input_shape=...),\n",
        "       keras.layers.MaxPooling2D(...),\n",
        "       keras.layers.Conv2D(..., ..., activation=\"relu\", padding=\"same\"),\n",
        "       keras.layers.Conv2D(..., ..., activation=\"relu\", padding=\"same\"),\n",
        "       keras.layers.MaxPooling2D(...),\n",
        "       keras.layers.Flatten(),\n",
        "       keras.layers.Dense(..., activation=\"relu\"),\n",
        "       keras.layers.Dropout(...),\n",
        "       keras.layers.Dense(..., activation=\"softmax\")\n",
        "])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conceptos**\n",
        "\n",
        "* Siempre usaremos un tamaño de kernel impar para que esté centrado en un píxel y el kernel se aplique de forma simétrica. Es preferible usar un tamaño de kernel pequeño (3x3) y apilar varias capas convolucionales, en vez de usar un tamaño de kernel mas grande (5x5), ya que podemos obtener una mejora similar con menos parámetros. En el caso de la primera capa conectada con el input, si que podemos usar un kernel mas grande con stride para reducir la dimensionalidad de la imágen.\n",
        "*  Incrementamos el número de kernels en cada capa convolucional a medida que esta se hace más profunda, ya que el número de características de bajo nivel en una imagen (vértices, lineas horizontales, círculos) es menor que el número de características de alto nivel (características complejas de la imagen que son combinacion de características de bajo nivel).\n",
        "\n",
        "*  Una pooling layer con una pool size de 2 divide cada dimension espacial entre 2.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3_5hs86B-704"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Actividad\n",
        "\n",
        "Las siguientes tareas ayudan a construir el esqueleto de una implementación básica de una CNN, pero las podeis adaptar a vuesta propia implementación. Para tener una buena performance tendreis que hacer encontrar los valores óptimos de los hiperparámetros de la red, y experimentar con distintas técnicas (regularización, dropout...).\n",
        "\n",
        "**Tarea 1:** Cargar y preprocesar el dataset."
      ],
      "metadata": {
        "id": "66W1rMe6JfTV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kz7ts0wwjGRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296cec3f-05f0-45b6-d011-717e20649275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "y_train shape: (60000,)\n",
            "x_test shape: (10000, 28, 28, 1)\n",
            "y_test shape: (10000,)\n"
          ]
        }
      ],
      "source": [
        "# Cargar el dataset MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalizar las imágenes a valores entre 0 y 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Añadir una dimensión extra para el canal (ya que las imágenes son en escala de grises)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "\n",
        "# Verificar las formas de los datos\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 2:** Definir la arquitectura del modelo.\n"
      ],
      "metadata": {
        "id": "p5wTMRo5Jvnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "i2AbU7IvJ14-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 3:** Compilar el modelo.\n"
      ],
      "metadata": {
        "id": "n_5N-yyUJ8bV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Kg5HDrwSJ-_o"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 4:** Aumentar los datos.\n"
      ],
      "metadata": {
        "id": "t2k_1WzwKAXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "[TIP] Utiliza ImageDataGenerator de Keras para aplicar técnicas de aumento de datos.\n",
        "\"\"\"\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n"
      ],
      "metadata": {
        "id": "AXK2V2jmKD9y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 5:** Entrenar el modelo.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nS5AcK3sKGGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=10, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "id": "Xk-Lj93WKIdN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e424662f-71ed-47bf-9e4c-59343c2ffda1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 95s 49ms/step - loss: 0.2398 - accuracy: 0.9243 - val_loss: 0.0465 - val_accuracy: 0.9853\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0832 - accuracy: 0.9742 - val_loss: 0.0278 - val_accuracy: 0.9906\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 71s 38ms/step - loss: 0.0621 - accuracy: 0.9808 - val_loss: 0.0375 - val_accuracy: 0.9894\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0526 - accuracy: 0.9839 - val_loss: 0.0300 - val_accuracy: 0.9903\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0449 - accuracy: 0.9868 - val_loss: 0.0316 - val_accuracy: 0.9899\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 72s 38ms/step - loss: 0.0417 - accuracy: 0.9871 - val_loss: 0.0172 - val_accuracy: 0.9945\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0396 - accuracy: 0.9883 - val_loss: 0.0203 - val_accuracy: 0.9936\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 0.0313 - val_accuracy: 0.9910\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0195 - val_accuracy: 0.9941\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.0325 - accuracy: 0.9901 - val_loss: 0.0219 - val_accuracy: 0.9923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 6:** Evaluar el modelo.\n"
      ],
      "metadata": {
        "id": "bDdknPOBKOT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "metadata": {
        "id": "SnboRGgqKQdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "447639dc-0e9d-4a97-c89f-536ce4f076aa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 8ms/step - loss: 0.0219 - accuracy: 0.9923\n",
            "Test accuracy: 0.9922999739646912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tarea 7**: **Transfer learning**. Importar un modelo preentrenado (e.gVGG16 o ResNet50) y adaptar su arquitectura para Fashion MNIST. Evaluar la performance del modelo, y comparalo con la CNN anterior."
      ],
      "metadata": {
        "id": "b-8olpjmGY33"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bUGrfvAsrYBi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}