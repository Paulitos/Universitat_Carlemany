{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **4A**"
      ],
      "metadata": {
        "id": "VHQVvoCnhxf3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jCLQRctfhhz-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c01d400d-ce25-4dbf-d35a-e2e673f19388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución para Pool con 14 procesos: 0.46199774742126465 segundos\n"
          ]
        }
      ],
      "source": [
        "# 4a\n",
        "import time\n",
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "\n",
        "def multiplicar_matrices(matriz):\n",
        "    A = matriz\n",
        "    # Generar matriz B con dimensiones compatibles con A\n",
        "    B = np.random.rand(*A.shape)  # B tendrá las mismas dimensiones que A\n",
        "    return np.dot(A, B)\n",
        "\n",
        "def ejecutar_con_pool(num_procesos, tamaño_matriz):\n",
        "    matriz_ejemplo = np.random.rand(*tamaño_matriz)\n",
        "    with mp.Pool(processes=num_procesos) as pool:\n",
        "        resultados = pool.map(multiplicar_matrices, [matriz_ejemplo] * num_procesos)\n",
        "    return resultados\n",
        "\n",
        "# Tamaño de la matriz y número de procesos para pruebas\n",
        "tamaño_matriz = (100, 100)  # Ejemplo de tamaño de matriz más pequeño\n",
        "num_procesos = mp.cpu_count() * 7  # Multiplicar por 7 veces el número de procesadores disponibles\n",
        "\n",
        "# Ejecutar y medir el tiempo de ejecución\n",
        "start_time = time.time()\n",
        "resultados = ejecutar_con_pool(num_procesos, tamaño_matriz)\n",
        "end_time = time.time()\n",
        "\n",
        "tiempo_ejecucion = end_time - start_time\n",
        "\n",
        "print(f\"Tiempo de ejecución para Pool con {num_procesos} procesos: {tiempo_ejecucion} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4B**"
      ],
      "metadata": {
        "id": "0cnA2aZN76Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4b\n",
        "def multiplicar_matrices_chunk(chunk):\n",
        "    A, B = chunk\n",
        "    return np.dot(A, B)\n",
        "\n",
        "def multiplicar_matrices_chunks(num_chunks, tamaño_matriz):\n",
        "    # Generar matriz A y matriz B con dimensiones compatibles\n",
        "    A = np.random.rand(*tamaño_matriz)\n",
        "    B = np.random.rand(*tamaño_matriz)\n",
        "\n",
        "    # Dividir A y B en chunks según el número de chunks especificado\n",
        "    chunks_A = np.array_split(A, num_chunks, axis=0)\n",
        "    chunks_B = np.array_split(B, num_chunks, axis=1)\n",
        "\n",
        "    # Empaquetar cada par de chunks A y B\n",
        "    chunks = [(chunks_A[i], chunks_B[i]) for i in range(num_chunks)]\n",
        "\n",
        "    # Utilizar multiprocessing para multiplicar las matrices en paralelo\n",
        "    with mp.Pool(processes=num_chunks) as pool:\n",
        "        resultados = pool.map(multiplicar_matrices_chunk, chunks)\n",
        "\n",
        "    # Concatenar los resultados de cada chunk en una única matriz\n",
        "    resultado_final = np.concatenate(resultados)\n",
        "\n",
        "    return resultado_final\n",
        "\n",
        "# Tamaño de la matriz y número de chunks para pruebas\n",
        "tamaño_matriz = (2000, 2000)\n",
        "num_chunks_list = [1, 2, 4, 8, 16]  # Variar el número de chunks\n",
        "\n",
        "# Ejecutar y medir el tiempo de ejecución para cada configuración\n",
        "for num_chunks in num_chunks_list:\n",
        "    start_time = time.time()\n",
        "    resultado = multiplicar_matrices_chunks(num_chunks, tamaño_matriz)\n",
        "    end_time = time.time()\n",
        "    tiempo_ejecucion = end_time - start_time\n",
        "\n",
        "    print(f\"Tiempo de ejecución para {num_chunks} chunks: {tiempo_ejecucion:.4f} segundos\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJt9EPwwueqp",
        "outputId": "b0bd6bf3-0f54-4cf7-c549-c562a7aba016"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tiempo de ejecución para 1 chunks: 1.7509 segundos\n",
            "Tiempo de ejecución para 2 chunks: 1.2333 segundos\n",
            "Tiempo de ejecución para 4 chunks: 1.0390 segundos\n",
            "Tiempo de ejecución para 8 chunks: 0.7903 segundos\n",
            "Tiempo de ejecución para 16 chunks: 0.8836 segundos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4C**"
      ],
      "metadata": {
        "id": "S9j08SwL71q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para encontrar la combinación idónea entre el número de procesos y la medida de los chunks que minimice el tiempo de ejecución en la multiplicación de matrices, podemos basarnos en los tiempos de ejecución obtenidos en las partes anteriores del ejercicio 4a y 4b. Aquí está el proceso seguido y las decisiones tomadas:\n",
        "\n",
        "**Análisis de los tiempos de ejecución:**\n",
        "\n",
        "1. **Tiempo de ejecución para Pool con 14 procesos:** 0.462 segundos\n",
        "   - Este tiempo nos da una referencia de cuánto toma ejecutar el código con 14 procesos. Es un tiempo bastante bajo, lo cual indica una buena eficiencia en paralelismo.\n",
        "\n",
        "2. **Tiempo de ejecución variando el número de chunks:**\n",
        "   - 1 chunk: 1.7509 segundos\n",
        "   - 2 chunks: 1.2333 segundos\n",
        "   - 4 chunks: 1.0390 segundos\n",
        "   - 8 chunks: 0.7903 segundos\n",
        "   - 16 chunks: 0.8836 segundos\n",
        "\n",
        "**Razonamiento y decisiones:**\n",
        "\n",
        "- **Número de procesos:** Basado en el tiempo de ejecución del Pool con 14 procesos (0.462 segundos), podemos inferir que utilizar un número cercano a 14 procesos es eficiente. Sin embargo, el tiempo de ejecución no se reduce linealmente con el número de procesos debido a otros factores de sobrecarga y administración del sistema.\n",
        "\n",
        "- **Número de chunks:** Observamos que a medida que aumentamos el número de chunks, el tiempo de ejecución disminuye hasta cierto punto. Luego, para un número mayor de chunks (más de 8 en este caso), el tiempo parece estabilizarse o incluso aumentar ligeramente. Esto puede deberse a la sobrecarga adicional de dividir y gestionar los chunks más pequeños.\n",
        "\n",
        "**Combinación idónea:**\n",
        "\n",
        "Para determinar la combinación idónea que minimice el tiempo de ejecución:\n",
        "\n",
        "- **Procesos:** Podemos considerar utilizar alrededor de 14 procesos, como se observó en la ejecución con Pool.\n",
        "- **Chunks:** Según los tiempos obtenidos, el tiempo más bajo se obtuvo con 8 chunks (0.7903 segundos). Aunque 16 chunks también tiene un tiempo similar (0.8836 segundos), puede ser beneficioso elegir un número ligeramente menor de chunks para reducir la complejidad de la gestión de los chunks.\n",
        "\n",
        "**Decisión final:**\n",
        "\n",
        "Una combinación razonable basada en los datos sería utilizar **14 procesos** con **8 chunks**. Esto equilibra el paralelismo proporcionado por los procesos con la eficiencia obtenida al dividir las matrices en chunks de tamaño moderado.\n",
        "\n",
        "Implementar esta combinación en el código y medir el tiempo de ejecución confirmará si es la más óptima para tu caso específico. Si se requiere mayor precisión, también se pueden realizar pruebas adicionales variando ligeramente el número de procesos o chunks y comparando los tiempos resultantes."
      ],
      "metadata": {
        "id": "5TZcIwCZyzoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4D**"
      ],
      "metadata": {
        "id": "5HNrtjJs8ABs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para calcular y analizar los parámetros T1, T∞, Tp, Sp y los recursos gastados para las ejecuciones del apartado 4, utilizaremos la información obtenida de los tiempos de ejecución para diferentes configuraciones de procesos y chunks. Aquí vamos a calcular y luego utilizar estos parámetros en nuestros razonamientos y decisiones:\n",
        "\n",
        "### Definición de términos:\n",
        "\n",
        "- **T1:** Tiempo de ejecución con un solo proceso.\n",
        "- **T∞:** Tiempo de ejecución con infinitos procesos, es decir, el límite inferior teórico del tiempo de ejecución.\n",
        "- **Tp:** Tiempo de ejecución con p procesos.\n",
        "- **Sp:** Aceleración de la ejecución utilizando p procesos en comparación con un solo proceso (Sp = T1 / Tp).\n",
        "- **Recursos gastados:** Refiere a la cantidad de recursos computacionales utilizados, que puede medirse en términos de memoria, CPU, tiempo de ejecución total, etc.\n",
        "\n",
        "### Pasos para el cálculo y análisis:\n",
        "\n",
        "1. **Calcular T1:** Utilizaremos el tiempo de ejecución con un solo proceso. Asumiremos que este es el tiempo mínimo teórico para la tarea (aunque en realidad podría ser más alto debido a la sobrecarga general del sistema).\n",
        "\n",
        "2. **Calcular T∞:** Aunque no es posible ejecutar con infinitos procesos, T∞ se considera el límite inferior teórico del tiempo de ejecución, que normalmente se aproxima al tiempo que tomaría la operación sin considerar ningún tipo de sobrecarga adicional.\n",
        "\n",
        "3. **Calcular Tp para cada configuración:** Utilizaremos los tiempos de ejecución medidos para 14 procesos y diferentes cantidades de chunks (1, 2, 4, 8, 16).\n",
        "\n",
        "4. **Calcular Sp para cada configuración:** Sp se calcula como la relación entre T1 y Tp (Sp = T1 / Tp). Este nos indicará cuánto más rápido es el procesamiento paralelo en comparación con el procesamiento secuencial.\n",
        "\n",
        "5. **Analizar recursos gastados:** Esto puede implicar revisar el uso de CPU, memoria, y cualquier otra métrica que sea relevante para determinar la eficiencia y la escalabilidad del sistema.\n",
        "\n",
        "### Ejemplo de cálculo:\n",
        "\n",
        "Tomaremos como ejemplo los tiempos de ejecución proporcionados anteriormente:\n",
        "\n",
        "- T1 (tiempo con un solo proceso): 1.7509 segundos (tomando el tiempo con 1 chunk).\n",
        "- T∞ (tiempo teórico con infinitos procesos): No se puede calcular directamente, pero se considera el límite inferior teórico.\n",
        "- Tp para diferentes configuraciones (14 procesos y diferentes números de chunks):\n",
        "  - Para 1 chunk: Tp = 1.7509 segundos\n",
        "  - Para 2 chunks: Tp = 1.2333 segundos\n",
        "  - Para 4 chunks: Tp = 1.0390 segundos\n",
        "  - Para 8 chunks: Tp = 0.7903 segundos\n",
        "  - Para 16 chunks: Tp = 0.8836 segundos\n",
        "\n",
        "### Calcular Sp para cada configuración:\n",
        "\n",
        "- Sp para 1 chunk: Sp = T1 / Tp = 1.7509 / 1.7509 = 1 (sin aceleración, pues es secuencial).\n",
        "- Sp para 2 chunks: Sp = 1.7509 / 1.2333 ≈ 1.42 (aproximadamente 1.42 veces más rápido).\n",
        "- Sp para 4 chunks: Sp = 1.7509 / 1.0390 ≈ 1.68 (aproximadamente 1.68 veces más rápido).\n",
        "- Sp para 8 chunks: Sp = 1.7509 / 0.7903 ≈ 2.22 (aproximadamente 2.22 veces más rápido).\n",
        "- Sp para 16 chunks: Sp = 1.7509 / 0.8836 ≈ 1.98 (aproximadamente 1.98 veces más rápido).\n",
        "\n",
        "### Análisis de recursos gastados:\n",
        "\n",
        "- Se debería considerar la carga de trabajo por proceso, la utilización de la memoria, y cualquier sobrecarga adicional del sistema al utilizar más procesos y chunks.\n",
        "\n",
        "### Toma de decisiones:\n",
        "\n",
        "- Basado en los resultados de Sp, se puede decidir qué configuración ofrece el mejor rendimiento en términos de velocidad de procesamiento.\n",
        "- Considerar también los recursos gastados para determinar cuál es la configuración más eficiente desde el punto de vista computacional.\n",
        "\n",
        "Utilizando estos parámetros, podemos hacer una elección más informada sobre la configuración óptima de procesos y chunks para minimizar el tiempo de ejecución y optimizar el uso de recursos en la multiplicación de matrices."
      ],
      "metadata": {
        "id": "n8jdMZEO7ZME"
      }
    }
  ]
}